<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[机器学习流程与问题解决架构模板]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fbkhomework190223.html</url>
    <content type="text"><![CDATA[个中等水平的数据科学家每天都要处理大量的数据。一些人说超过60%到70%的时间都用于数据清理、数据处理及格式转化，以便于在之后应用机器学习模型。这篇文章的重点便在后者—— 应用机器学习模型（包括预处理的阶段）。此文讨论到的内容来源于我参加的过的数百次的机器学习竞赛。请大家注意这里讨论的方法是大体上适用的，当然还有很多被专业人士使用的非常复杂的方法。接下来会使用到python。 数据在应用机器学习模型之前，所有的数据都必须转换为表格形式。如下图所示，这个过程是最耗时、最困难的部分。转换完成之后，便可以将这些表格数据灌入机器学习模型。表格数据是在机器学习或是数据挖掘中最常见的数据表示形式。我们有一个数据表，x轴是样本数据，y轴是标签。标签可以是单列可以是多列，取决于问题的形式。我们会用X表示数据，y表示标签。 标签的种类标签会定义你要解决何种问题，有不同的问题类型。例如： 单列，二进制值（分类问题，一个样本仅属于一个类，并且只有两个类） 单列，实数值（回归问题，只预测一个值） 多列，二进制值（分类问题，一个样本属于一个类，但有两个以上的类） 多列，实数值（回归问题，多个值的预测） 多个标签（分类问题，一个样本可以属于几个类）评估指标 对于任何类型的机器学习问题，我们都一定要知道如何评估结果，或者说评估指标和目的是什么。举例来说，对于不均衡的二进制分类问题，我们通常选择受试者工作特征曲线下面积（ROC AUC或简单的AUC）；对于多标签或多类别的分类问题，我们通常选择分类交叉熵或多类对数损失；对于回归问题，则会选择均方差。 我不会再深入的讲解不同的评估指标，因为根据问题的不同会有很多不同的种类。 库开始尝试机器学习库可以从安装最基础也是最重要的开始，像numpy和scipy。 查看和执行数据操作：pandas（http://pandas.pydata.org/） 对于各种机器学习模型：scikit-learn（http://scikit-learn.org/stable/） 最好的gradient boosting库：xgboost（https://github.com/dmlc/xgboost） 对于神经网络：keras（http://keras.io/） 数据绘图：matplotlib（http://matplotlib.org/） 监视进度：tqdm（https://pypi.python.org/pypi/tqdm）Anaconda操作简单而且帮你准备好了这些，可是我没有使用，因为我习惯自己配置和自由使用。当然，决策在你手中。 机器学习总体框架2017起，我开始制作一个自动机器学习框架，还在完善过程中，很快就会发布。下图所示的框架图就是这篇文章中将会提到的基础框架： 上面的框架图中，粉色的线代表最常用的路径。结束提取数据并将其转化为表格形式，我们就可以开始建造机器学习模型了。 应用算法解决 Kaggle 问题，一般有以下几个步骤： 第一步：识别问题 第二步：分离数据 第三步：构造提取特征 第四步：组合数据 第五步：分解 第六步：选择特征 第七步：选择算法进行训练当然，工欲善其事，必先利其器，要先把工具和包都安好。 最方便的就是安装 Anaconda，这里面包含大部分数据科学所需要的包，直接引入就可以了，常用的包有： pandas：常用来将数据转化成 dataframe 形式进行操作 scikit-learn：里面有要用到的机器学习算法模型 matplotlib：用来画图 以及 xgboost，keras，tqdm 等。 第一步：识别问题在这一步先明确这个问题是分类还是回归。通过问题和数据就可以判断出来，数据由 X 和 label 列构成，label 可以一列也可以多列，可以是二进制也可以是实数，当它为二进制时，问题属于分类，当它为实数时，问题属于回归。 第二步：分离数据 为什么需要将数据分成两部分？ 用 Training Data 来训练模型，用 Validation Data 来检验这个模型的表现，不然的话，通过各种调节参数，模型可以在训练数据集上面表现的非常出色，但是这可能会是过拟合，过拟合就是太依赖现有的数据了，拟合的效果特别好，但是只适用于训练集，以致于来一个新的数据，就不知道该预测成什么了。所以需要有 Validation 来验证一下，看这个模型是在那里自娱自乐呢，还是真的表现出色。 在 scikit learn 包里就有工具可以帮你做到这些：分类问题用 StrtifiedKFold from sklearn.cross_validation import StratifiedKFold 回归问题用 KFold from sklearn.cross_validation import KFold 第三步：构造特征这个时候，需要将数据转化成模型需要的形式。数据有三种类型：数字，类别，文字。当数据是类别的形式时，需要将它的每一类提取出来作为单独一列，然后用二进制表示每条记录相应的值。例如： record 1: 性别 女record 2：性别 女record 3：性别 男 转化之后就是： 女 男record 1: 1 0record 2：1 0record 3：0 1 这个过程 sklearn 也可以帮你做到： from sklearn.preprocessing import LabelEncoder 或者 from sklearn.preprocessing import OneHotEncoder 第四步：组合数据处理完 Feature 之后，就将它们组合到一起。如果数据是稠密的，就可以用 numpy 的 hstack: import numpy as npX = np.hstack((x1, x2, …)) 如果是稀疏的，就用 sparse 的 hstack： from scipy import sparseX = sparse.hstack((x1, x2, …)) 组合之后，就可以应用以下算法模型： RandomForestClassifier RandomForestRegressor ExtraTreesClassifier ExtraTreesRegressor XGBClassifier XGBRegressor 但是不能应用线性模型，线性模型之前需要对数据进行正则化而不是上述预处理。 第五步：分解这一步是为了进一步优化模型，可以用以下方法： PCA：Principal components analysis，主成分分析，是一种分析、简化数据集的技术。用于减少数据集的维数，同时保持数据集中的对方差贡献最大的特征。 from sklearn.decomposition import PCA 对于文字数据，在转化成稀疏矩阵之后，可以用 SVD from sklearn.decomposition import TruncatedSVD SVD：Singular Value Decomposition，奇异值分解，是线性代数中一种重要的矩阵分解，它总能找到标准化正交基后方差最大的维度，因此用它进行降维去噪 第六步：选择特征当特征个数越多时，分析特征、训练模型所需的时间就越长，容易引起“维度灾难”，模型也会越复杂，推广能力也会下降，所以需要剔除不相关或亢余的特征。 常用的算法有完全搜索，启发式搜索，和随机算法。 例如，Random Forest： from sklearn.ensemble import RandomForestClassifier 或者 xgboost： import xgboost as xgb 对于稀疏的数据，一个比较有名的方法是 chi-2： from sklearn.feature_selection import SelectKBestfrom sklearn.feature_selection import chi2 第七步：选择算法进行训练选择完最相关的参数之后，接下来就可以应用算法，常用的算法有 Classification: Random Forest GBM Logistic Regression Naive Bayes Support Vector Machines k-Nearest Neighbors Regression Random Forest GBM Linear Regression Ridge Lasso SVR 在scikit－learn里可以看到分类和回归的可用的算法一览，包括它们的原理和例子代码。 在应用各算法之前先要明确这个方法到底是否合适。为什么那么多算法里，只提出这几个算法呢，这就需要对比不同算法的性能了。这篇神文 Do we Need Hundreds of Classifiers to Solve Real World Classification Problems 测试了179种分类模型在UCI所有的121个数据上的性能，发现Random Forests 和 SVM 性能最好。我们可以学习一下里面的调研思路，看看是怎么样得到比较结果的，在我们的实践中也有一定的指导作用。 但是直接应用算法后，一般精度都不是很理想，这个时候需要调节参数，最干货的问题来了，什么模型需要调节什么参数呢？ 虽然在sklearn的文档里，会列出所有算法所带有的参数，但是里面并不会说调节哪个会有效。在一些mooc课程里，有一些项目的代码，里面可以看到一些算法应用时，他们重点调节的参数，但是有的也不会说清楚为什么不调节别的。这里作者根据他100多次比赛的经验，列出了这个表，我觉得可以借鉴一下，当然，如果有时间的话，去对照文档里的参数列表，再查一下算法的原理，通过理论也是可以判断出来哪个参数影响比较大的。 调参之后，也并不就是大功告成，这个时候还是需要去思考，是什么原因造成精度低的，是哪些数据的深意还没有被挖掘到，这个时候需要用统计和可视化去再一次探索数据，之后就再走一遍上面的过程。 我觉得这里还提到了很有用的一条经验是，把所有的 transformer 都保存起来，方便在 validation 数据集上面应用： 文章里介绍了分析问题的思路，还提到了几条很实用的经验，不过经验终究是别人的经验，只能借鉴，要想提高自己的水平，还是要看到作者背后的事情，就是参加了100多次实战，接下来就去行动吧，享受用算法和代码与数据玩耍的兴奋吧。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>新手入门任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习特征选择]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fbkhomework190224.html</url>
    <content type="text"><![CDATA[sklearn.feature_selection模块中的类可用于样本集上的特征选择/降维，以提高估计者的准确度分数或提高其在非常高维数据集上的性能。 删除方差低的要素VarianceThreshold是一种简单的特征选择基线方法。它会删除方差不符合某个阈值的所有要素。默认情况下，它会删除所有零方差要素，即在所有样本中具有相同值的要素。 例如，假设我们有一个具有布尔特征的数据集，并且我们希望删除80％以上样本中的一个或零（打开或关闭）的所有特征。布尔特征是伯努利随机变量，这些变量的方差由下式给出 所以我们可以选择使用阈值：.8 * (1 - .8) 12345678910from sklearn import preprocessingimport numpy as npX_train = np.array([[ 1., -1., 2.], [ 2., 0., 0.], [ 0., 1., -1.]])X_scaled = preprocessing.scale(X_train)X_scaled array([[ 0. ..., -1.22..., 1.33...], [ 1.22..., 0. ..., -0.26...], [-1.22..., 1.22..., -1.06...]]) 缩放数据的均值和单位方差为零：12X_scaled 。mean （axis = 0 ）X_scaled 。std （axis = 0 ） 该preprocessing模块还提供实用程序类StandardScaler，该实用程序类 实现TransformerAPI以计算训练集上的均值和标准偏差，以便稍后能够在测试集上重新应用相同的变换。因此，该类适用于以下的早期步骤 sklearn.pipeline.Pipeline： 1234567891011scaler = preprocessing.StandardScaler().fit(X_train)scalerscaler.mean_ scaler.scale_ scaler.transform(X_train) 然后，可以将缩放器实例用于新数据，以便像在训练集上一样对其进行转换： X_test = [[-1., 1., 0.]] scaler.transform(X_test) array([[-2.44…, 1.22…, -0.26…]]) 可以通过传递with_mean=False或with_std=False构造函数来禁用居中或缩放StandardScaler。 将功能扩展到范围另一种标准化是将特征缩放到给定的最小值和最大值之间，通常在0和1之间，或者使每个特征的最大绝对值按比例缩放到单位大小。这可以分别使用MinMaxScaler或实现MaxAbsScaler。 使用此缩放的动机包括对特征的非常小的标准偏差的鲁棒性以及在稀疏数据中保留零条目。 以下是将玩具数据矩阵缩放到范围的示例：[0, 1] X_train = np.array([[ 1., -1., 2.], … [ 2., 0., 0.], … [ 0., 1., -1.]]) … min_max_scaler = preprocessing.MinMaxScaler() X_train_minmax = min_max_scaler.fit_transform(X_train) X_train_minmax array([[0.5 , 0. , 1. ], [1. , 0.5 , 0.33333333], [0. , 1. , 0. ]]) 然后可以将相同的变压器实例应用于在拟合调用期间看不到的一些新测试数据：将应用相同的缩放和移位操作以与对列车数据执行的变换一致： X_test = np.array([[-3., -1., 4.]]) X_test_minmax = min_max_scaler.transform(X_test) X_test_minmax array([[-1.5 , 0. , 1.66666667]]) 可以反省缩放器属性以查找在训练数据上学习的转换的确切性质： min_max_scaler.scale_ array([0.5 , 0.5 , 0.33…]) min_max_scaler.min_ array([0. , 0.5 , 0.33…]) 如果MinMaxScaler给出明确的完整公式是：feature_range=(min, max) X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) X_scaled = X_std * (max - min) + min MaxAbsScaler以非常类似的方式工作，但通过划分每个特征中的最大最大值，以训练数据在该范围内的方式进行缩放。它适用于已经以零或稀疏数据为中心的数据。[-1, 1] 以下是如何使用此缩放器使用上一个示例中的玩具数据： X_train = np.array([[ 1., -1., 2.], … [ 2., 0., 0.], … [ 0., 1., -1.]]) … max_abs_scaler = preprocessing.MaxAbsScaler() X_train_maxabs = max_abs_scaler.fit_transform(X_train) X_train_maxabs # doctest +NORMALIZE_WHITESPACE^ array([[ 0.5, -1. , 1. ], [ 1. , 0. , 0. ], [ 0. , 1. , -0.5]]) X_test = np.array([[ -3., -1., 4.]]) X_test_maxabs = max_abs_scaler.transform(X_test) X_test_maxabs array([[-1.5, -1. , 2. ]]) max_abs_scaler.scale_ array([2., 1., 2.]) 至于scale，该模块还提供了方便的函数 minmax_scale和maxabs_scale，如果你不希望创建一个对象。 缩放稀疏数据将稀疏数据居中会破坏数据中的稀疏结构，因此很少是明智之举。但是，缩放稀疏输入是有意义的，尤其是在特征不同的情况下。 MaxAbsScaler 并且maxabs_scale专门用于扩展稀疏数据，是推荐的解决方案。但是， 只要显式传递给构造函数，scale并且StandardScaler可以接受scipy.sparse矩阵作为输入with_mean=False。否则ValueError会产生一个静音中心会破坏稀疏性并且通常会无意中分配过多的内存而导致执行崩溃。 RobustScaler不能适应稀疏输入，但您可以transform在稀疏输入上使用该方法。 请注意，缩放器接受Compressed Sparse Rows和Compressed Sparse Columns格式（请参阅scipy.sparse.csr_matrix和 scipy.sparse.csc_matrix）。任何其他稀疏输入将转换为Compressed Sparse Rows表示。为避免不必要的内存复制，建议在上游选择CSR或CSC表示。 最后，如果预期中心数据足够小，则使用toarray稀疏矩阵的方法显式地将输入转换为数组是另一种选择。 使用异常值缩放数据如果您的数据包含许多异常值，则使用数据的均值和方差进行缩放可能效果不佳。在这些情况下，您可以使用 robust_scale和RobustScaler替代插入式替换。他们对数据的中心和范围使用更可靠的估计。 参考文献： 有关集中和缩放数据重要性的进一步讨论，请参阅此常见问题解答：我应该对数据进行标准化/标准化/重新调整吗？ 缩放与美白 由于下游模型可以进一步对特征的线性独立性做出一些假设，有时不足以独立地对中心和缩放特征。 为了解决这个问题，你可以用sklearn.decomposition.PCA用 whiten=True，以进一步去除跨功能的线性相关。 缩放1D阵列 所有上述功能（即scale，minmax_scale， maxabs_scale，和robust_scale）接受一维数组，其可以在某些特定的情况下是有用的。 居中核矩阵如果你有一个内核的内核矩阵 计算由函数定义的特征空间中的点积 ，a KernelCenterer可以转换内核矩阵，使其包含由定义的特征空间中的内积 然后删除该空间中的平均值。 非线性变换映射到统一分布与缩放器一样，QuantileTransformer将所有特征放入相同的已知范围或分布中。然而，通过执行秩变换，它可以平滑不寻常的分布，并且受到异常值的影响小于缩放方法。然而，它确实扭曲了特征内部和特征之间的相关性和距离。 QuantileTransformer并quantile_transform提供基于分位数函数的非参数变换，将数据映射到0到1之间的均匀分布： from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split iris = load_iris() X, y = iris.data, iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) quantile_transformer = preprocessing.QuantileTransformer(random_state=0) X_train_trans = quantile_transformer.fit_transform(X_train) X_test_trans = quantile_transformer.transform(X_test) np.percentile(X_train[:, 0], [0, 25, 50, 75, 100]) array([ 4.3, 5.1, 5.8, 6.5, 7.9]) 此功能对应于以cm为单位的萼片长度。应用分位数变换后，这些地标接近先前定义的百分位数： np.percentile(X_train_trans[:, 0], [0, 25, 50, 75, 100]) … array([ 0.00… , 0.24…, 0.49…, 0.73…, 0.99… ]) 这可以在具有类似评论的独立测试集上确认： np.percentile(X_test[:, 0], [0, 25, 50, 75, 100]) … array([ 4.4 , 5.125, 5.75 , 6.175, 7.3 ]) np.percentile(X_test_trans[:, 0], [0, 25, 50, 75, 100]) … array([ 0.01…, 0.25…, 0.46…, 0.60… , 0.94…]) 映射到高斯分布在许多建模方案中，期望数据集中的特征的正常性。功率变换是一系列参数单调变换，旨在将来自任何分布的数据映射到尽可能接近高斯分布，以便稳定方差并最小化偏度。 PowerTransformer 目前提供两种这样的功率变换，即Yeo-Johnson变换和Box-Cox变换。 Box-Cox只能应用于严格的正数据。在这两种方法中，转换都通过参数化，这是通过最大似然估计确定的。下面是使用Box-Cox将从对数正态分布绘制的样本映射到正态分布的示例： pt = preprocessing.PowerTransformer(method=’box-cox’, standardize=False) X_lognormal = np.random.RandomState(616).lognormal(size=(3, 3)) X_lognormal array([[1.28…, 1.18…, 0.84…], [0.94…, 1.60…, 0.38…], [1.35…, 0.21…, 1.09…]]) pt.fit_transform(X_lognormal) array([[ 0.49…, 0.17…, -0.15…], [-0.05…, 0.58…, -0.57…], [ 0.69…, -0.84…, 0.10…]]) 虽然上面的示例将standardize选项设置为False，但 PowerTransformer默认情况下将零均值单位方差归一化应用于变换后的输出。 以下是应用于各种概率分布的Box-Cox和Yeo-Johnson的示例。请注意，当应用于某些分布时，功率变换实现非常类似高斯的结果，但是对于其他分布，它们是无效的。这突出了在转换之前和之后可视化数据的重要性。 也可以使用QuantileTransformer设置将数据映射到正态分布 output_distribution=’normal’。将前面的示例与iris数据集一起使用： quantile_transformer = preprocessing.QuantileTransformer( … output_distribution=’normal’, random_state=0) X_trans = quantile_transformer.fit_transform(X) quantile_transformer.quantiles_ array([[4.3…, 2…, 1…, 0.1…], [4.31…, 2.02…, 1.01…, 0.1…], [4.32…, 2.05…, 1.02…, 0.1…], …, [7.84…, 4.34…, 6.84…, 2.5…], [7.87…, 4.37…, 6.87…, 2.5…], [7.9…, 4.4…, 6.9…, 2.5…]]) 因此，输入的中值变为输出的平均值，以0为中心。正常输出被削减，使得输入的最小值和最大值 - 分别对应于1e-7和1 - 1e-7分位数 - 不会变为无穷大转型。 规范化归一化是将单个样本缩放为具有单位范数的过程。如果您计划使用二次形式（如点积或任何其他内核）来量化任何样本对的相似性，则此过程非常有用。 此假设是常用于文本分类和聚类上下文的向量空间模型的基础。 该函数normalize提供了一种快速简便的方法，可以使用l1或l2 规范在单个类数据集上执行此操作 X = [[ 1., -1., 2.], … [ 2., 0., 0.], … [ 0., 1., -1.]] X_normalized = preprocessing.normalize(X, norm=’l2’) X_normalized array([[ 0.40…, -0.40…, 0.81…], [ 1. …, 0. …, 0. …], [ 0. …, 0.70…, -0.70…]]) 该preprocessing模块还提供了一个实用程序类 Normalizer，它使用TransformerAPI 实现相同的操作 （即使该fit方法在这种情况下无用：该类是无状态的，因为此操作独立地处理样本）。 因此，该类适用于以下的早期步骤 sklearn.pipeline.Pipeline： normalizer = preprocessing.Normalizer().fit(X) # fit does nothing normalizer Normalizer(copy=True, norm=’l2’) 然后，规范化器实例可以作为任何变换器用于样本向量： normalizer.transform(X) array([[ 0.40…, -0.40…, 0.81…], [ 1. …, 0. …, 0. …], [ 0. …, 0.70…, -0.70…]]) normalizer.transform([[-1., 1., 0.]]) array([[-0.70…, 0.70…, 0. …]]) 稀疏输入 normalize并Normalizer接受来自scipy.sparse的密集数组和稀疏矩阵作为输入。 对于稀疏输入，数据在被送入有效的Cython例程之前被转换为Compressed Sparse Rows表示（请参阅scipy.sparse.csr_matrix参考资料）。为避免不必要的内存复制，建议在上游选择CSR表示。 编码分类功能通常，特征不是连续值而是分类。例如，一个人可能具备的功能， ， 。这样的功能可以有效地编码为整数，例如 可以表示为 ，而将 。[“male”, “female”][“from Europe”, “from US”, “from Asia”][“uses Firefox”, “uses Chrome”, “uses Safari”, “uses Internet Explorer”][“male”, “from US”, “uses Internet Explorer”][0, 1, 3][“female”, “from Asia”, “uses Chrome”][1, 2, 1] 要将分类特征转换为此类整数代码，我们可以使用 OrdinalEncoder。此估计器将每个分类特征转换为整数的一个新特征（0到n_categories - 1）： enc = preprocessing.OrdinalEncoder() X = [[‘male’, ‘from US’, ‘uses Safari’], [‘female’, ‘from Europe’, ‘uses Firefox’]] enc.fit(X) OrdinalEncoder(categories=’auto’, dtype=&lt;… ‘numpy.float64’&gt;) enc.transform([[‘female’, ‘from US’, ‘uses Safari’]]) array([[0., 1., 1.]]) 然而，这样的整数表示不能直接用于所有scikit-learn估计器，因为它们期望连续输入，并且将类别解释为有序的，这通常是不期望的（即，浏览器集是任意排序的）。 将分类特征转换为可与scikit-learn估计器一起使用的特征的另一种可能性是使用一个K，也称为一热或虚拟编码。这种类型的编码可以通过以下方式获得：OneHotEncoder将每个分类特征与 n_categories可能的值转换为n_categories二进制特征，其中一个为1，其他为0。 继续上面的例子： enc = preprocessing.OneHotEncoder() X = [[‘male’, ‘from US’, ‘uses Safari’], [‘female’, ‘from Europe’, ‘uses Firefox’]] enc.fit(X) OneHotEncoder(categorical_features=None, categories=None, dtype=&lt;… ‘numpy.float64’&gt;, handle_unknown=’error’, n_values=None, sparse=True) enc.transform([[‘female’, ‘from US’, ‘uses Safari’], … [‘male’, ‘from Europe’, ‘uses Safari’]]).toarray() array([[1., 0., 0., 1., 0., 1.], [0., 1., 1., 0., 0., 1.]]) 默认情况下，每个要素可以采用的值是从数据集中自动推断出来的，可以在categories_属性中找到： enc.categories_ [array([‘female’, ‘male’], dtype=object), array([‘from Europe’, ‘from US’], dtype=object), array([‘uses Firefox’, ‘uses Safari’], dtype=object)] 可以使用参数显式指定它categories。我们的数据集中有两种性别，四种可能的大陆和四种Web浏览器： genders = [‘female’, ‘male’] locations = [‘from Africa’, ‘from Asia’, ‘from Europe’, ‘from US’] browsers = [‘uses Chrome’, ‘uses Firefox’, ‘uses IE’, ‘uses Safari’] enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers]) Note that for there are missing categorical values for the 2nd and 3rd feature X = [[‘male’, ‘from US’, ‘uses Safari’], [‘female’, ‘from Europe’, ‘uses Firefox’]] enc.fit(X) OneHotEncoder(categorical_features=None, categories=[…], dtype=&lt;… ‘numpy.float64’&gt;, handle_unknown=’error’, n_values=None, sparse=True) enc.transform([[‘female’, ‘from Asia’, ‘uses Chrome’]]).toarray() array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]]) 如果训练数据可能缺少分类特征，则通常可以更好地指定handle_unknown=’ignore’而不是categories如上所述手动设置。如果 handle_unknown=’ignore’在转换期间遇到指定和未知类别，则不会引发错误，但此功能的结果单热编码列将全为零（handle_unknown=’ignore’仅支持单热编码）： enc = preprocessing.OneHotEncoder(handle_unknown=’ignore’) X = [[‘male’, ‘from US’, ‘uses Safari’], [‘female’, ‘from Europe’, ‘uses Firefox’]] enc.fit(X) OneHotEncoder(categorical_features=None, categories=None, dtype=&lt;… ‘numpy.float64’&gt;, handle_unknown=’ignore’, n_values=None, sparse=True) enc.transform([[‘female’, ‘from Asia’, ‘uses Chrome’]]).toarray() array([[1., 0., 0., 0., 0., 0.]]) 请参阅从dicts加载功能，了解表示为dict的分类功能，而不是标量。 离散离散化 （也称为量化或分级）提供了将连续特征划分为离散值的方法。具有连续特征的某些数据集可以从离散化中受益，因为离散化可以将连续属性的数据集转换为仅具有标称属性的数据集。 单热编码离散化功能可以使模型更具表现力，同时保持可解释性。例如，使用离散器进行预处理可以为线性模型引入非线性。 K-bin离散化特征二值化遗漏值的估算生成多项式特征自定义变换器【注】引用于 scikit-learn链接]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>新手入门任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习算法解决思路与建议]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fbkhomework190221.html</url>
    <content type="text"><![CDATA[本次的目的是对于kaggle入门的新手要求，学会机器学习算法解决思路。打卡！！！ 1.引言实战练习提起笔来写这篇博客，突然有点愧疚和尴尬。愧疚的是，工作杂事多，加之懒癌严重，导致这个系列一直没有更新，向关注该系列的同学们道个歉。尴尬的是，按理说，机器学习介绍与算法一览应该放在最前面写，详细的应用建议应该在讲完机器学习常用算法之后写，突然莫名奇妙在中间插播这么一篇，好像有点打乱主线。老话说『亡羊补牢，为时未晚』，前面开头忘讲的东西，咱在这块儿补上。我们先带着大家过一遍传统机器学习算法，基本思想和用途。把问题解决思路和方法应用建议提前到这里的想法也很简单，希望能提前给大家一些小建议，对于某些容易出错的地方也先给大家打个预防针，这样在理解后续相应机器学习算法之后，使用起来也有一定的章法。 2.机器学习算法简述按照不同的分类标准，可以把机器学习的算法做不同的分类。 2.1 从机器学习问题角度分类我们先从机器学习问题本身分类的角度来看，我们可以分成下列类型的算法： 监督学习算法 机器学习中有一大部分的问题属于『监督学习』的范畴，简单口语化地说明，这类问题中，给定的训练样本中，每个样本的输入x都对应一个确定的结果y，我们需要训练出一个模型(数学上看是一个x→y的映射关系f)，在未知的样本x′给定后，我们能对结果y′做出预测。 这里的预测结果如果是离散值(很多时候是类别类型，比如邮件分类问题中的垃圾邮件/普通邮件，比如用户会/不会购买某商品)，那么我们把它叫做分类问题(classification problem)；如果预测结果是连续值(比如房价，股票价格等等)，那么我们把它叫做回归问题(regression problem)。有一系列的机器学习算法是用以解决监督学习问题的，比如最经典的用于分类问题的朴素贝叶斯、逻辑回归、支持向量机等等；比如说用于回归问题的线性回归等等。 无监督学习算法 有另外一类问题，给我们的样本并没有给出『标签/标准答案』，就是一系列的样本。而我们需要做的事情是，在一些样本中抽取出通用的规则。这叫做『无监督学习』。包括关联规则和聚类算法在内的一系列机器学习算法都属于这个范畴。 半监督学习算法 这类问题给出的训练数据，有一部分有标签，有一部分没有标签。我们想学习出数据组织结构的同时，也能做相应的预测。此类问题相对应的机器学习算法有自训练(Self-Training)、直推学习(Transductive Learning)、生成式模型(Generative Model)等。 总体说来，最常见是前两类问题，而对应前两类问题的一些机器学习算法如下： 2.2 从算法的功能角度分类我们也可以从算法的共性(比如功能，运作方式)角度对机器学习算法分类。下面我们根据算法的共性去对它们归个类。不过需要注意的是，我们下面的归类方法可能对分类和回归有比较强的倾向性，而这两类问题也是最常遇到的。 2.2.1 回归算法(Regression Algorithms) 回归算法是一种通过最小化预测值与实际结果值之间的差距，而得到输入特征之间的最佳组合方式的一类算法。对于连续值预测有线性回归等，而对于离散值/类别预测，我们也可以把逻辑回归等也视作回归算法的一种，常见的回归算法如下： Ordinary Least Squares Regression (OLSR) Linear Regression Logistic Regression Stepwise Regression Locally Estimated Scatterplot Smoothing (LOESS) Multivariate Adaptive Regression Splines (MARS) 2.2.2 基于实例的算法(Instance-based Algorithms) 这里所谓的基于实例的算法，我指的是我们最后建成的模型，对原始数据样本实例依旧有很强的依赖性。这类算法在做预测决策时，一般都是使用某类相似度准则，去比对待预测的样本和原始样本的相近度，再给出相应的预测结果。常见的基于实例的算法有： k-Nearest Neighbour (kNN) Learning Vector Quantization (LVQ) Self-Organizing Map (SOM) Locally Weighted Learning (LWL) 2.2.3 决策树类算法(Decision Tree Algorithms) 决策树类算法，会基于原始数据特征，构建一颗包含很多决策路径的树。预测阶段选择路径进行决策。常见的决策树算法包括： Classification and Regression Tree (CART) Iterative Dichotomiser 3 (ID3) C4.5 and C5.0 (different versions of a powerful approach) Chi-squared Automatic Interaction Detection (CHAID) M5 Conditional Decision Trees 2.2.4 贝叶斯类算法(Bayesian Algorithms) 这里说的贝叶斯类算法，指的是在分类和回归问题中，隐含使用了贝叶斯原理的算法。包括： Naive Bayes Gaussian Naive Bayes Multinomial Naive Bayes Averaged One-Dependence Estimators (AODE) Bayesian Belief Network (BBN) Bayesian Network (BN) 2.2.5 聚类算法(Clustering Algorithms) 聚类算法做的事情是，把输入样本聚成围绕一些中心的『数据团』，以发现数据分布结构的一些规律。常用的聚类算法包括： k-Means Hierarchical Clustering Expectation Maximisation (EM) 2.2.6 关联规则算法(Association Rule Learning Algorithms) 关联规则算法是这样一类算法：它试图抽取出，最能解释观察到的训练样本之间关联关系的规则，也就是获取一个事件和其他事件之间依赖或关联的知识，常见的关联规则算法有： Apriori algorithm Eclat algorithm 2.2.7 人工神经网络类算法(Artificial Neural Network Algorithms) 这是受人脑神经元工作方式启发而构造的一类算法。需要提到的一点是，我把『深度学习』单拎出来了，这里说的人工神经网络偏向于更传统的感知算法，主要包括： Perceptron Back-Propagation Radial Basis Function Network (RBFN) 2.2.8 深度学习(Deep Learning Algorithms) 深度学习是近年来非常火的机器学习领域，相对于上面列的人工神经网络算法，它通常情况下，有着更深的层次和更复杂的结构。有兴趣的同学可以看看我们另一个系列机器学习与计算机视觉，最常见的深度学习算法包括： Deep Boltzmann Machine (DBM) Deep Belief Networks (DBN) Convolutional Neural Network (CNN) Stacked Auto-Encoders 2.2.9 降维算法(Dimensionality Reduction Algorithms) 从某种程度上说，降维算法和聚类其实有点类似，因为它也在试图发现原始训练数据的固有结构，但是降维算法在试图，用更少的信息(更低维的信息)总结和描述出原始信息的大部分内容。有意思的是，降维算法一般在数据的可视化，或者是降低数据计算空间有很大的作用。它作为一种机器学习的算法，很多时候用它先处理数据，再灌入别的机器学习算法学习。主要的降维算法包括： Principal Component Analysis (PCA) Principal Component Regression (PCR) Partial Least Squares Regression (PLSR) Sammon Mapping Multidimensional Scaling (MDS) Linear Discriminant Analysis (LDA) Mixture Discriminant Analysis (MDA) Quadratic Discriminant Analysis (QDA) 2.2.10 模型融合算法(Ensemble Algorithms) 严格意义上来说，这不算是一种机器学习算法，而更像是一种优化手段/策略，它通常是结合多个简单的弱机器学习算法，去做更可靠的决策。拿分类问题举个例，直观的理解，就是单个分类器的分类是可能出错，不可靠的，但是如果多个分类器投票，那可靠度就会高很多。常用的模型融合增强方法包括： Random Forest Boosting Bootstrapped Aggregation (Bagging) AdaBoost Stacked Generalization (blending) Gradient Boosting Machines (GBM) Gradient Boosted Regression Trees (GBRT) 2.3 机器学习算法使用图谱scikit-learn作为一个丰富的python机器学习库，实现了绝大多数机器学习的算法，有相当多的人在使用，于是我这里很无耻地把machine learning cheat sheet for sklearn搬过来了，原文可以看这里。哈哈，既然讲机器学习，我们就用机器学习的语言来解释一下，这是针对实际应用场景的各种条件限制，对scikit-learn里完成的算法构建的一颗决策树，每一组条件都是对应一条路径，能找到相对较为合适的一些解决方法，具体如下： 首先样本量如果非常少的话，其实所有的机器学习算法都没有办法从里面『学到』通用的规则和模式，so多弄点数据是王道。然后根据问题是有/无监督学习和连续值/离散值预测，分成了分类、聚类、回归和维度约减四个方法类，每个类里根据具体情况的不同，又有不同的处理方法。 #3. 机器学习问题解决思路 上面带着代价走马观花过了一遍机器学习的若干算法，下面我们试着总结总结在拿到一个实际问题的时候，如果着手使用机器学习算法去解决问题，其中的一些注意点以及核心思路。主要包括以下内容： 拿到数据后怎么了解数据(可视化) 选择最贴切的机器学习算法 定位模型状态(过/欠拟合)以及解决方法 大量极的数据的特征分析与可视化 各种损失函数(loss function)的优缺点及如何选择多说一句，这里写的这个小教程，主要是作为一个通用的建议和指导方案，你不一定要严格按照这个流程解决机器学习问题。 3.1 数据与可视化我们先使用scikit-learn的make_classification函数来生产一份分类数据，然后模拟一下拿到实际数据后我们需要做的事情。12345678#numpy科学计算工具箱import numpy as np#使用make_classification构造1000个样本，每个样本有20个featurefrom sklearn.datasets import make_classificationX, y = make_classification(1000, n_features=20, n_informative=2,n_redundant=2, n_classes=2, random_state=0)#存为dataframe格式from pandas import DataFramedf = DataFrame(np.hstack((X, y[:, None])),columns = range(20) + [&quot;class&quot;]) 我们生成了一份包含1000个分类数据样本的数据集，每个样本有20个数值特征。同时我们把数据存储至pandas中的DataFrame数据结构中。我们取前几行的数据看一眼： 1df[:6] 不幸的是，肉眼看数据，尤其是维度稍微高点的时候，很有可能看花了也看不出看不出任何线索。幸运的是，我们对于图像的理解力，比数字好太多，而又有相当多的工具可以帮助我们『可视化』数据分布 我们在处理任何数据相关的问题时，了解数据都是很有必要的，而可视化可以帮助我们更好地直观理解数据的分布和特性 数据的可视化有很多工具包可以用，比如下面我们用来做数据可视化的工具包Seaborn。最简单的可视化就是数据散列分布图和柱状图，这个可以用Seanborn的pairplot来完成。以下图中2种颜色表示2种不同的类，因为20维的可视化没有办法在平面表示，我们取出了一部分维度，两两组成pair看数据在这2个维度平面上的分布状况，代码和结果如下： 12345import matplotlib.pyplot as pltimport seaborn as sns#使用pairplot去看不同特征维度pair下数据的空间分布状况_ = sns.pairplot(df[:50], vars=[8, 11, 12, 14, 19], hue=&quot;class&quot;, size=1.5)plt.show() 我们从散列图和柱状图上可以看出，确实有些维度的特征相对其他维度，有更好的区分度，比如第11维和14维看起来很有区分度。这两个维度上看，数据点是近似线性可分的。而12维和19维似乎呈现出了很高的负相关性。接下来我们用Seanborn中的corrplot来计算计算各维度特征之间(以及最后的类别)的相关性。代码和结果图如下：1234import matplotlib.pyplot as pltplt.figure(figsize=(12, 10))_ = sns.corrplot(df, annot=False)plt.show() 相关性图很好地印证了我们之前的想法，可以看到第11维特征和第14维特征和类别有极强的相关性，同时它们俩之间也有极高的相关性。而第12维特征和第19维特征却呈现出极强的负相关性。强相关的特征其实包含了一些冗余的特征，而除掉上图中颜色较深的特征，其余特征包含的信息量就没有这么大了，它们和最后的类别相关度不高，甚至各自之间也没什么先惯性。 插一句，这里的维度只有20，所以这个相关度计算并不费太大力气，然而实际情形中，你完全有可能有远高于这个数字的特征维度，同时样本量也可能多很多，那种情形下我们可能要先做一些处理，再来实现可视化了。别着急，一会儿我们会讲到。 3.2 机器学习算法选择数据的情况我们大致看了一眼，确定一些特征维度之后，我们可以考虑先选用机器学习算法做一个baseline的系统出来了。这里我们继续参照上面提到过的机器学习算法使用图谱。我们只有1000个数据样本，是分类问题，同时是一个有监督学习，因此我们根据图谱里教的方法，使用LinearSVC(support vector classification with linear kernel)试试。注意，LinearSVC需要选择正则化方法以缓解过拟合问题；我们这里选择使用最多的L2正则化，并把惩罚系数C设为10。我们改写一下sklearn中的学习曲线绘制函数，画出训练集和交叉验证集上的得分： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748from sklearn.svm import LinearSVCfrom sklearn.learning_curve import learning_curve#绘制学习曲线，以确定模型的状况def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, train_sizes=np.linspace(.1, 1.0, 5)): &quot;&quot;&quot; 画出data在某模型上的learning curve. 参数解释 ---------- estimator : 你用的分类器。 title : 表格的标题。 X : 输入的feature，numpy类型 y : 输入的target vector ylim : tuple格式的(ymin, ymax), 设定图像中纵坐标的最低点和最高点 cv : 做cross-validation的时候，数据分成的份数，其中一份作为cv集，其余n-1份作为training(默认为3份) &quot;&quot;&quot; plt.figure() train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=5, n_jobs=1, train_sizes=train_sizes) train_scores_mean = np.mean(train_scores, axis=1) train_scores_std = np.std(train_scores, axis=1) test_scores_mean = np.mean(test_scores, axis=1) test_scores_std = np.std(test_scores, axis=1) plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=&quot;r&quot;) plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=&quot;g&quot;) plt.plot(train_sizes, train_scores_mean, &apos;o-&apos;, color=&quot;r&quot;, label=&quot;Training score&quot;) plt.plot(train_sizes, test_scores_mean, &apos;o-&apos;, color=&quot;g&quot;, label=&quot;Cross-validation score&quot;) plt.xlabel(&quot;Training examples&quot;) plt.ylabel(&quot;Score&quot;) plt.legend(loc=&quot;best&quot;) plt.grid(&quot;on&quot;) if ylim: plt.ylim(ylim) plt.title(title) plt.show()#少样本的情况情况下绘出学习曲线plot_learning_curve(LinearSVC(C=10.0), &quot;LinearSVC(C=10.0)&quot;, X, y, ylim=(0.8, 1.01), train_sizes=np.linspace(.05, 0.2, 5)) 这幅图上，我们发现随着样本量的增加，训练集上的得分有一定程度的下降，交叉验证集上的得分有一定程度的上升，但总体说来，两者之间有很大的差距，训练集上的准确度远高于交叉验证集。这其实意味着我们的模型处于过拟合的状态，也即模型太努力地刻画训练集，一不小心把很多噪声的分布也拟合上了，导致在新数据上的泛化能力变差了。 3.2.1 过拟合的定位与解决问题来了，过拟合咋办？针对过拟合，有几种办法可以处理： 增大样本量这个比较好理解吧，过拟合的主要原因是模型太努力地去记住训练样本的分布状况，而加大样本量，可以使得训练集的分布更加具备普适性，噪声对整体的影响下降。恩，我们提高点样本量试试： 1234#增大一些样本量plot_learning_curve(LinearSVC(C=10.0), &quot;LinearSVC(C=10.0)&quot;, X, y, ylim=(0.8, 1.1), train_sizes=np.linspace(.1, 1.0, 5)) 是不是发现问题好了很多？随着我们增大训练样本量，我们发现训练集和交叉验证集上的得分差距在减少，最后它们已经非常接近了。增大样本量，最直接的方法当然是想办法去采集相同场景下的新数据，如果实在做不到，也可以试试在已有数据的基础上做一些人工的处理生成新数据(比如图像识别中，我们可能可以对图片做镜像变换、旋转等等)，当然，这样做一定要谨慎，强烈建议想办法采集真实数据。 减少特征的量(只用我们觉得有效的特征)比如在这个例子中，我们之前的数据可视化和分析的结果表明，第11和14维特征包含的信息对识别类别非常有用，我们可以只用它们。 1plot_learning_curve(LinearSVC(C=10.0), &quot;LinearSVC(C=10.0) Features: 11&amp;14&quot;, X[:, [11, 14]], y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5)) 从上图上可以看出，过拟合问题也得到一定程度的缓解。不过我们这是自己观察后，手动选出11和14维特征。那能不能自动进行特征组合和选择呢，其实我们当然可以遍历特征的组合样式，然后再进行特征选择(前提依旧是这里特征的维度不高，如果高的话，遍历所有的组合是一个非常非常非常耗时的过程！！)： 123456from sklearn.pipeline import Pipelinefrom sklearn.feature_selection import SelectKBest, f_classif# SelectKBest(f_classif, k=2) 会根据Anova F-value选出 最好的k=2个特征plot_learning_curve(Pipeline([(&quot;fs&quot;, SelectKBest(f_classif, k=2)), # select two features (&quot;svc&quot;, LinearSVC(C=10.0))]), &quot;SelectKBest(f_classif, k=2) + LinearSVC(C=10.0)&quot;, X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5)) 如果你自己跑一下程序，会发现在我们自己手造的这份数据集上，这个特征筛选的过程超级顺利，但依旧像我们之前提过的一样，这是因为特征的维度不太高。从另外一个角度看，我们之所以做特征选择，是想降低模型的复杂度，而更不容易刻画到噪声数据的分布。从这个角度出发，我们还可以有(1)多项式你和模型中降低多项式次数 (2)神经网络中减少神经网络的层数和每层的结点数 ©SVM中增加RBF-kernel的bandwidth等方式来降低模型的复杂度。话说回来，即使以上提到的办法降低模型复杂度后，好像能在一定程度上缓解过拟合，但是我们一般还是不建议一遇到过拟合，就用这些方法处理，优先用下面的方法： 增强正则化作用(比如说这里是减小LinearSVC中的C参数)正则化是我认为在不损失信息的情况下，最有效的缓解过拟合现象的方法。 1plot_learning_curve(LinearSVC(C=0.1), &quot;LinearSVC(C=0.1)&quot;, X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5)) 调整正则化系数后，发现确实过拟合现象有一定程度的缓解，但依旧是那个问题，我们现在的系数是自己敲定的，有没有办法可以自动选择最佳的这个参数呢？可以。我们可以在交叉验证集上做grid-search查找最好的正则化系数(对于大数据样本，我们依旧需要考虑时间问题，这个过程可能会比较慢): 1234567from sklearn.grid_search import GridSearchCVestm = GridSearchCV(LinearSVC(), param_grid=&#123;&quot;C&quot;: [0.001, 0.01, 0.1, 1.0, 10.0]&#125;)plot_learning_curve(estm, &quot;LinearSVC(C=AUTO)&quot;, X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5))print &quot;Chosen parameter on 100 datapoints: %s&quot; % estm.fit(X[:500], y[:500]).best_params_ 在500个点得到的结果是：{‘C’: 0.01}使用新的C参数，我们再看看学习曲线： 对于特征选择的部分，我打算多说几句，我们刚才看过了用sklearn.feature_selection中的SelectKBest来选择特征的过程，也提到了在高维特征的情况下，这个过程可能会非常非常慢。那我们有别的办法可以进行特征选择吗？比如说，我们的分类器自己能否甄别那些特征是对最后的结果有益的？这里有个实际工作中用到的小技巧。 我们知道： l2正则化，它对于最后的特征权重的影响是，尽量打散权重到每个特征维度上，不让权重集中在某些维度上，出现权重特别高的特征。 而l1正则化，它对于最后的特征权重的影响是，让特征获得的权重稀疏化，也就是对结果影响不那么大的特征，干脆就拿不着权重。 那基于这个理论，我们可以把SVC中的正则化替换成l1正则化，让其自动甄别哪些特征应该留下权重。1plot_learning_curve(LinearSVC(C=0.1, penalty=&apos;l1&apos;, dual=False), &quot;LinearSVC(C=0.1, penalty=&apos;l1&apos;)&quot;, X, y, ylim=(0.8, 1.0), train_sizes=np.linspace(.05, 0.2, 5)) 好了，我们一起来看看最后特征获得的权重：1234estm = LinearSVC(C=0.1, penalty=&apos;l1&apos;, dual=False)estm.fit(X[:450], y[:450]) # 用450个点来训练print &quot;Coefficients learned: %s&quot; % est.coef_print &quot;Non-zero coefficients: %s&quot; % np.nonzero(estm.coef_)[1] 得到结果：12345Coefficients learned: [[ 0. 0. 0. 0. 0. 0.01857999 0. 0. 0. 0.004135 0. 1.05241369 0.01971419 0. 0. 0. 0. -0.05665314 0.14106505 0. ]]Non-zero coefficients: [5 9 11 12 17 18] 你看，5 9 11 12 17 18这些维度的特征获得了权重，而第11维权重最大，也说明了它影响程度最大。 3.2.2 欠拟合定位与解决我们再随机生成一份数据[1000*20]的数据(但是分布和之前有变化)，重新使用LinearSVC来做分类12345#构造一份环形数据from sklearn.datasets import make_circlesX, y = make_circles(n_samples=1000, random_state=2)#绘出学习曲线plot_learning_curve(LinearSVC(C=0.25),&quot;LinearSVC(C=0.25)&quot;,X, y, ylim=(0.5, 1.0),train_sizes=np.linspace(.1, 1.0, 5)) 简直烂出翔了有木有，二分类问题，我们做随机猜测，准确率都有0.5，这比随机猜测都高不了多少！！！怎么办？ 不要盲目动手收集更多资料，或者调整正则化参数。我们从学习曲线上其实可以看出来，训练集上的准确度和交叉验证集上的准确度都很低，这其实就对应了我们说的『欠拟合』状态。别急，我们回到我们的数据，还是可视化看看： 12f = DataFrame(np.hstack((X, y[:, None])), columns = range(2) + [&quot;class&quot;])_ = sns.pairplot(df, vars=[0, 1], hue=&quot;class&quot;, size=3.5) 你发现什么了，数据根本就没办法线性分割！！！，所以你再找更多的数据，或者调整正则化参数，都是无济于事的！！！ 那我们又怎么解决欠拟合问题呢？通常有下面一些方法：123# 加入原始特征的平方项作为新特征X_extra = np.hstack((X, X[:, [0]]**2 + X[:, [1]]**2))plot_learning_curve(LinearSVC(C=0.25), &quot;LinearSVC(C=0.25) + distance feature&quot;, X_extra, y, ylim=(0.5, 1.0), train_sizes=np.linspace(.1, 1.0, 5)) 卧槽，少年，这准确率，被吓尿了有木有啊！！！所以你看，选用的特征影响太大了，当然，我们这里是人工模拟出来的数据，分布太明显了，实际数据上，会比这个麻烦一些，但是在特征上面下的功夫还是很有回报的。 使用更复杂一点的模型(比如说用非线性的核函数)我们对模型稍微调整了一下，用了一个复杂一些的非线性rbf kernel： 123from sklearn.svm import SVC# note: we use the original X without the extra featureplot_learning_curve(SVC(C=2.5, kernel=&quot;rbf&quot;, gamma=1.0), &quot;SVC(C=2.5, kernel=&apos;rbf&apos;, gamma=1.0)&quot;,X, y, ylim=(0.5, 1.0), train_sizes=np.linspace(.1, 1.0, 5)) 你看，效果依旧很赞。 3.3 关于大数据样本集和高维特征空间我们在小样本的toy dataset上，怎么捣鼓都有好的方法。但是当数据量和特征样本空间膨胀非常厉害时，很多东西就没有那么好使了，至少是一个很耗时的过程。举个例子说，我们现在重新生成一份数据集，但是这次，我们生成更多的数据，更高的特征维度，而分类的类别也提高到5。 3.3.1 大数据情形下的模型选择与学习曲线在上面提到的那样一份数据上，我们用LinearSVC可能就会有点慢了，我们注意到机器学习算法使用图谱推荐我们使用SGDClassifier。其实本质上说，这个模型也是一个线性核函数的模型，不同的地方是，它使用了随机梯度下降做训练，所以每次并没有使用全部的样本，收敛速度会快很多。再多提一点，SGDClassifier对于特征的幅度非常敏感，也就是说，我们在把数据灌给它之前，应该先对特征做幅度调整，当然，用sklearn的StandardScaler可以很方便地完成这一点。 SGDClassifier每次只使用一部分(mini-batch)做训练，在这种情况下，我们使用交叉验证(cross-validation)并不是很合适，我们会使用相对应的progressive validation：简单解释一下，estimator每次只会拿下一个待训练batch在本次做评估，然后训练完之后，再在这个batch上做一次评估，看看是否有优化。 1234567891011121314151617181920212223#生成大样本，高纬度特征数据X, y = make_classification(200000, n_features=200, n_informative=25, n_redundant=0, n_classes=10, class_sep=2, random_state=0)#用SGDClassifier做训练，并画出batch在训练前后的得分差from sklearn.linear_model import SGDClassifierest = SGDClassifier(penalty=&quot;l2&quot;, alpha=0.001)progressive_validation_score = []train_score = []for datapoint in range(0, 199000, 1000): X_batch = X[datapoint:datapoint+1000] y_batch = y[datapoint:datapoint+1000] if datapoint &gt; 0: progressive_validation_score.append(est.score(X_batch, y_batch)) est.partial_fit(X_batch, y_batch, classes=range(10)) if datapoint &gt; 0: train_score.append(est.score(X_batch, y_batch)) plt.plot(train_score, label=&quot;train score&quot;)plt.plot(progressive_validation_score, label=&quot;progressive validation score&quot;)plt.xlabel(&quot;Mini-batch&quot;)plt.ylabel(&quot;Score&quot;)plt.legend(loc=&apos;best&apos;) plt.show() 得到如下的结果： 从这个图上的得分，我们可以看出在50个mini-batch迭代之后，数据上的得分就已经变化不大了。但是好像得分都不太高，所以我们猜测一下，这个时候我们的数据，处于欠拟合状态。我们刚才在小样本集合上提到了，如果欠拟合，我们可以使用更复杂的模型，比如把核函数设置为非线性的，但遗憾的是像rbf核函数是没有办法和SGDClassifier兼容的。因此我们只能想别的办法了，比如这里，我们可以把SGDClassifier整个替换掉了，用多层感知神经网来完成这个任务，我们之所以会想到多层感知神经网，是因为它也是一个用随机梯度下降训练的算法，同时也是一个非线性的模型。当然根据机器学习算法使用图谱，也可以使用核估计(kernel-approximation)来完成这个事情。 3.3.2 大数据量下的可视化大样本数据的可视化是一个相对比较麻烦的事情，一般情况下我们都要用到降维的方法先处理特征。我们找一个例子来看看，可以怎么做，比如我们数据集取经典的『手写数字集』，首先找个方法看一眼这个图片数据集。12345678910111213141516171819202122#直接从sklearn中load数据集from sklearn.datasets import load_digitsdigits = load_digits(n_class=6)X = digits.datay = digits.targetn_samples, n_features = X.shapeprint &quot;Dataset consist of %d samples with %d features each&quot; % (n_samples, n_features)# 绘制数字示意图n_img_per_row = 20img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))for i in range(n_img_per_row): ix = 10 * i + 1 for j in range(n_img_per_row): iy = 10 * j + 1 img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))plt.imshow(img, cmap=plt.cm.binary)plt.xticks([])plt.yticks([])_ = plt.title(&apos;A selection from the 8*8=64-dimensional digits dataset&apos;)plt.show() 我们总共有1083个训练样本，包含手写数字(0,1,2,3,4,5)，每个样本图片中的像素点平铺开都是64位，这个维度显然是没办法直接可视化的。下面我们基于scikit-learn的示例教程对特征用各种方法做降维处理，再可视化。 随机投射 我们先看看，把数据随机投射到两个维度上的结果：1234567891011121314151617181920212223242526272829303132333435363738#import所需的packagefrom sklearn import (manifold, decomposition, random_projection)rp = random_projection.SparseRandomProjection(n_components=2, random_state=42)#定义绘图函数from matplotlib import offsetboxdef plot_embedding(X, title=None): x_min, x_max = np.min(X, 0), np.max(X, 0) X = (X - x_min) / (x_max - x_min) plt.figure(figsize=(10, 10)) ax = plt.subplot(111) for i in range(X.shape[0]): plt.text(X[i, 0], X[i, 1], str(digits.target[i]), color=plt.cm.Set1(y[i] / 10.), fontdict=&#123;&apos;weight&apos;: &apos;bold&apos;, &apos;size&apos;: 12&#125;) if hasattr(offsetbox, &apos;AnnotationBbox&apos;): # only print thumbnails with matplotlib &gt; 1.0 shown_images = np.array([[1., 1.]]) # just something big for i in range(digits.data.shape[0]): dist = np.sum((X[i] - shown_images) ** 2, 1) if np.min(dist) &lt; 4e-3: # don&apos;t show points that are too close continue shown_images = np.r_[shown_images, [X[i]]] imagebox = offsetbox.AnnotationBbox( offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r), X[i]) ax.add_artist(imagebox) plt.xticks([]), plt.yticks([]) if title is not None: plt.title(title)#记录开始时间start_time = time.time()X_projected = rp.fit_transform(X)plot_embedding(X_projected, &quot;Random Projection of the digits (time: %.3fs)&quot; % (time.time() - start_time)) 结果如下： PCA降维 在维度约减/降维领域有一个非常强大的算法叫做PCA(Principal Component Analysis，主成分分析)，它能将原始的绝大多数信息用维度远低于原始维度的几个主成分表示出来。PCA在我们现在的数据集上效果还不错，我们来看看用PCA对原始特征降维至2维后，原始样本在空间的分布状况123456from sklearn import (manifold, decomposition, random_projection)#TruncatedSVD 是 PCA的一种实现X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)#记录时间start_time = time.time()plot_embedding(X_pca,&quot;Principal Components projection of the digits (time: %.3fs)&quot; % (time.time() - start_time)) 得到的结果如下： 我们可以看出，效果还不错，不同的手写数字在2维平面上，显示出了区域集中性。即使它们之间有一定的重叠区域。 如果我们用一些非线性的变换来做降维操作，从原始的64维降到2维空间，效果更好，比如这里我们用到一个技术叫做t-SNE，sklearn的manifold对其进行了实现：12345678from sklearn import (manifold, decomposition, random_projection)#降维tsne = manifold.TSNE(n_components=2, init=&apos;pca&apos;, random_state=0)start_time = time.time()X_tsne = tsne.fit_transform(X)#绘图plot_embedding(X_tsne, &quot;t-SNE embedding of the digits (time: %.3fs)&quot; % (time.time() - start_time)) 我们发现结果非常的惊人，似乎这个非线性变换降维过后，仅仅2维的特征，就可以将原始数据的不同类别，在平面上很好地划分开。不过t-SNE也有它的缺点，一般说来，相对于线性变换的降维，它需要更多的计算时间。也不太适合在大数据集上全集使用 3.4 损失函数的选择损失函数的选择对于问题的解决和优化，非常重要。我们先来看一眼各种不同的损失函数123456789101112131415161718192021import numpy as npimport matplotlib.plot as plt# 改自http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.htmlxmin, xmax = -4, 4xx = np.linspace(xmin, xmax, 100)plt.plot([xmin, 0, 0, xmax], [1, 1, 0, 0], &apos;k-&apos;, label=&quot;Zero-one loss&quot;)plt.plot(xx, np.where(xx &lt; 1, 1 - xx, 0), &apos;g-&apos;, label=&quot;Hinge loss&quot;)plt.plot(xx, np.log2(1 + np.exp(-xx)), &apos;r-&apos;, label=&quot;Log loss&quot;)plt.plot(xx, np.exp(-xx), &apos;c-&apos;, label=&quot;Exponential loss&quot;)plt.plot(xx, -np.minimum(xx, 0), &apos;m-&apos;, label=&quot;Perceptron loss&quot;)plt.ylim((0, 8))plt.legend(loc=&quot;upper right&quot;)plt.xlabel(r&quot;Decision function $f(x)$&quot;)plt.ylabel(&quot;$L(y, f(x))$&quot;)plt.show() 得到结果图像如下： 0-1损失函数(zero-one loss)非常好理解，直接对应分类问题中判断错的个数。但是比较尴尬的是它是一个非凸函数，这意味着其实不是那么实用。 hinge loss(SVM中使用到的)的健壮性相对较高(对于异常点/噪声不敏感)。但是它没有那么好的概率解释。 log损失函数(log-loss)的结果能非常好地表征概率分布。因此在很多场景，尤其是多分类场景下，如果我们需要知道结果属于每个类别的置信度，那这个损失函数很适合。缺点是它的健壮性没有那么强，相对hinge loss会对噪声敏感一些。 多项式损失函数(exponential loss)(AdaBoost中用到的)对离群点/噪声非常非常敏感。但是它的形式对于boosting算法简单而有效。 感知损失(perceptron loss)可以看做是hinge loss的一个变种。hinge loss对于判定边界附近的点(正确端)惩罚力度很高。而perceptron loss，只要样本的判定类别结果是正确的，它就是满意的，而不管其离判定边界的距离。优点是比hinge loss简单，缺点是因为不是max-margin boundary，所以得到模型的泛化能力没有hinge loss强。 4. 总结全文到此就结束了。先走马观花看了一遍机器学习的算法，然后给出了对应scikit-learn的『秘密武器』机器学习算法使用图谱，紧接着从了解数据(可视化)、选择机器学习算法、定位过/欠拟合及解决方法、大量极的数据可视化和损失函数优缺点与选择等方面介绍了实际机器学习问题中的一些思路和方法。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>新手入门任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客修改日志]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%B7%A5%E5%85%B7%2FBlogLog.html</url>
    <content type="text"><![CDATA[记录本网站Next的所有所有修改 下载Next 6主题最简单的安装方式是直接克隆整个仓库： 12$ cd hexo$ git clone https://github.com/theme-next/hexo-theme-next themes/next 对主题配置文件进行修改在主题目录中找到\themes\next\languages\zh_CN.yml增加 123menu: code: 学习 life: 生活 在主题目录中找到\themes\next\languages\_config.yml 12345menu: home: / || home code: /categories/学习/ || heartbeat life: /categories/生活/ || calendar categories: /categories/ || th 第78行 关闭Hexo支持，和主题 12345678910powered: # Hexo link (Powered by Hexo). enable: false # Version info of Hexo after Hexo link (vX.X.X). version: truetheme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: false # Version info of NexT after scheme info (vX.X.X). version: true 第496行 还没改以后可以改 1han: false 第839行 设置点击图片可以全屏 fancybox: true 12cd themes/nextgit clone https://github.com/theme-next/theme-next-fancybox3 source/lib/fancybox 第872行 背景动画 12345cd themes/nextgit clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nestcanvas_nest: enable: true]]></content>
      <categories>
        <category>生活</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客索引]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2FBlogIndex.html</url>
    <content type="text"><![CDATA[记录本网站所有的文档，访客可以通过本页面看博客中的所有内容 机器学习入门机器学习入门（一）机器学习入门（二）交通仿真随手记博客修改日志]]></content>
      <categories>
        <category>生活</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[报账备忘录]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%8A%9E%E5%85%AC%2F%E6%8A%A5%E8%B4%A6%E5%A4%87%E5%BF%98.html</url>
    <content type="text"><![CDATA[在计财处报账需要准备的东西 报账时需要有《成信报销单》+发票+刷POS的小票 计财处报账时间：工作日的上午：上午9-11点和下午14-16点 学生代老师去报销需要带上“授权委托书”。 报销单内容： 签名齐全 备注栏需要写，姓名，工资号，和工资卡号。（张** #2848 2360） 公务卡支付的每一笔都需要在备注栏写明刷卡时间和金额 POS单小票贴在对应的发票上面，将所有的发票粘在报销单后 如果报销自行打印的书籍，需要在后面附上该打印书籍的照片。 如果单笔（发票连号，开发票的时间地点公司均一致视为一笔）报销金额超过一万元，则需要带上供销合同复印件。 如果汇款方，和所盖章上的名称有所出入（如收款为某某局盖章为某某编辑部）需要给予纸质证明。（如打印杂志的封面或扉页，找到该杂志由某某局主办）]]></content>
      <categories>
        <category>生活</category>
        <category>办公</category>
      </categories>
      <tags>
        <tag>琐碎</tag>
        <tag>随手记</tag>
        <tag>计财处</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习入门教程03]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fbkhomework180124.html</url>
    <content type="text"><![CDATA[实验室学生已经学会Python基本语法和数据预处理的知识，接下来可以尝试学习一些经典机器学习算法知识了。本次任务目的：主要是引导学生建立起一个记笔记的习惯。其次是熟悉常用的Python包 近两个星期的学习任务： 给出少量学生买电脑数据： 学习数据预处理，熟练使用Numpy&amp;pandas&amp;Matplotlib 经过python放到决策树算法中运行 学习Dtree算法过程，使用十字交叉法测试出数据预测准确率 使用python matplotlib画出Dtree运算过程中决策树的变化过程 总结学习过程 如果学习遇到问题可以参考我的Dtree项目代码和结果图 链接 【注】：建议同学们尽可能多的，把你们的学习总结成文档。（多参考技术类博客的教程是怎么做的）。另：本文介绍的软件我不做强制要求。只要能到达目的就好。比如还可以往GitHub里上传Jupyter的文件，如果有代码的时候最好用Jupyter。 【注2】：同学们做完的可以提前联系我。我好安排下一阶段的任务。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>新手入门教程</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习入门任务02]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fbkhomework180915.html</url>
    <content type="text"><![CDATA[实验室学生已经学会Python基本语法了，接下来可以尝试学习数据预处理的一些知识了。本次任务目的：主要是引导学生建立起一个记笔记的习惯。其次是熟悉常用的Python包 近两个星期的学习任务： 在GitHub/GitLab注册账号，较为熟练的使用Git操作。建议使用 GitHub for Desktop 学习markdown，用哪个软件不做要求。以后学习笔记都使用markdown语法。 在GitHub/GitLab上建立一个笔记库。以后的学习笔记都必须上传到库中，我才认为你学会了。（注：如果用GitLab需将库权限设定为public） 学习数据预处理，熟练使用Numpy&amp;pandas&amp;Matplotlib 实战练习：数据包 每步操作，代码，相关注释都要在笔记上有体现能用Jupyter就最好了 压缩包中《宝洁数据》具体任务如图所示 那个洗发水的数据第一步要转成这个样子，这里的每一行，是一笔店铺洗发水销售流水。关于根据数据画什么图？因为不能告知大家具体的项目背景，所以我不做要求，以练手为主。只要笔记里写明白是怎么画的就好。（最好用Jupyter） 根据压缩包中《气象数据》，绘制历年的平均气温变化图，平均降水量变化图，其他自由发挥。 安装CiteSpace ：CiteSpace介绍，在网上找个教程先了解软件的基础操作。 如果用Jupyter：请参考格式1 如果用markdown：请参考格式2 格式3 (说明：格式2 虽然也是使用了Jupyter，但是它主要用的是markdown，下载下来看一遍就知道了) 【注】：建议同学们尽可能多的，把你们的学习总结成文档。（多参考技术类博客的教程是怎么做的）。另：本文介绍的软件我不做强制要求。只要能到达目的就好。比如还可以往GitHub里上传Jupyter的文件，如果有代码的时候最好用Jupyter。 【注2】：同学们做完的可以提前联系我。我好安排下一阶段的任务。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>新手入门任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运行tensorflow出现FutureWarning]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%B7%A5%E5%85%B7%2F%E7%90%90%E7%A2%8E%2FTensorFlowWarning.html</url>
    <content type="text"><![CDATA[运行tensorflow出现FutureWarning，这个意义不大 在win10 64位运行tensorflow出现问题： 1FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.from ._conv import register_converters as _register_converters。 经过查阅资料,解决方法： 1pip install h5py==2.8.0rc1]]></content>
      <categories>
        <category>生活</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>琐碎</tag>
        <tag>随手记</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开局域网]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%B7%A5%E5%85%B7%2F%E7%90%90%E7%A2%8E%2F%E5%B1%80%E5%9F%9F%E7%BD%91%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[在命令行窗口下操作 在cmd命令行窗口下输入以下命令，对方就可以通过WiFi链接进入建立好的局域网。 前提：win10+无线网卡 123netsh wlan set hostednetwork mode=allow ssid=zconding key=12345678netsh wlan start hostednetwork]]></content>
      <categories>
        <category>生活</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>琐碎</tag>
        <tag>随手记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[饥荒作弊命令]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E6%B8%B8%E6%88%8F%2F%E9%A5%A5%E8%8D%92.html</url>
    <content type="text"><![CDATA[饥荒作弊命令 123456789# 显示全图minimap = TheSim:FindFirstEntityWithTag("minimap")minimap.MiniMap:ShowArea(0,0,0, 10000)# 将玩家传送到坐标【-55，97】上GetPlayer().Transform:SetPosition(-55,0,97)# 开启上帝建筑模式GetPlayer().components.builder:GiveAllRecipes()]]></content>
      <categories>
        <category>生活</category>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>饥荒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习入门任务01]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%2Fbkhomework180914.html</url>
    <content type="text"><![CDATA[学习前提：有一定的编程基础（学过C语言基础语法，能熟练使用循环判断等语句，掌握排序算法） 学习任务： 在GitHub/GitLab注册账号，较为熟练的使用Git操作。建议使用 GitHub for Desktop 学习markdown，用哪个软件不做要求。以后学习笔记都使用markdown语法。 在GitHub/GitLab上建立一个笔记库。以后的学习笔记都必须上传到库中，我才认为你学会了。（注：如果用GitLab需将库权限设定为public）笔记的最好用如果用Jupyter：请参考格式1或者是markdown 搭建python环境，强烈建议安装anaconda3+PyCharm 学习Python基础语法，做一个成绩管理系统，至少达到如下需求： 输入并存储学生的信息：通过输入学生的学号、姓名、和分数，然后就可以把数据保存在建立的student文件里面。 打印学生的所有信息：通过一个打印函数就可以把所有的信息打印在屏幕上。 修改学生信息：这个功能首先通过查询功能查询出该学生是否存在，如果存在就对该学生的信息进行修改，如果不存在则返回到主界面。 删除学生信息：该功能是对相应的学生进行删除操作，如果学生存在就查找到进行删除。 按学生成绩进行排序： 这个功能是按照学生的成绩进行排序，对学生的信息进行操作。 查找学生信息：这个功能通过输入学号，查找该学生的信息，如果有该学号就输出该学生的信息，没有该学号就提示输入的学号不存在。 例子 如果用Jupyter：请参考格式1 如果用markdown：请参考格式2 格式3 (说明：格式2 虽然也是使用了Jupyter，但是它主要用的是markdown，下载下来看一遍就知道了) 【注】：建议同学们尽可能多的，把你们的学习总结成文档。（多参考技术类博客的教程是怎么做的）。另：本文介绍的软件我不做强制要求。只要能到达目的就好。比如还可以往GitHub里上传Jupyter的文件，如果有代码的时候最好用Jupyter。 【注2】：同学们做完的可以提前联系我。我好安排下一阶段的任务。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>新手入门任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSM地图文件转SUMO]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E4%BA%A4%E9%80%9A%E4%BB%BF%E7%9C%9F%2FSUMO%E6%93%8D%E4%BD%9C%E6%95%99%E7%A8%8B.html</url>
    <content type="text"><![CDATA[将OSM文件转换成可以在SUMO中运行的路网文件 12345netconvert --osm-files map.osm -o map.net.xmlpolyconvert --net-file map.net.xml --osm-files map.osm --type-file typemap.xml -o map.poly.xmlpython "C:/Program Files (x86)/eclipse/Sumo/tools/randomTrips.py" -n map.net.xml -r map.rou.xml -e 100 -l]]></content>
      <categories>
        <category>学习</category>
        <category>交通仿真</category>
      </categories>
      <tags>
        <tag>OSM</tag>
        <tag>SUMO</tag>
        <tag>琐碎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在ubuntu下安装Flow]]></title>
    <url>%2F%E5%AD%A6%E4%B9%A0%2F%E4%BA%A4%E9%80%9A%E4%BB%BF%E7%9C%9F%2FInstall_FLow.html</url>
    <content type="text"><![CDATA[Flow是个基于SUMO的交通仿真程序，但是苦于不支持Windows系统，只支持Linux/MacOS系统。本文就是记录怎安装该软件 flow：Flow是一种用于交通微观仿真的深度RL和控制实验的计算框架。 一、前期环境准备1.1 Ubuntu换源参考链接：https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ 12sudo cp /etc/apt/sources.list /etc/apt/sources.list.oldsudo gedit /etc/apt/source.list 1.1 安装git1sudo apt-get install gits 1.2 安装Anaconda下载好.sh 文件 然后直接在命令行下运行 anaconda 换源 1234567conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --set show_channel_urls yes## 设置环境变量gedit ~/.bashrcexport PATH="/opt/STM/STLinux-2.3/devkit/sh4/bin:$PATH" 1.3 安装PyCharm1./******.sh 第一步：安装Flow 123456789git clone https://github.com/flow-project/flow.gitcd flow# create a conda environmentconda env create -f environment.ymlsource activate flowpython setup.py develop./scripts/setup_sumo_ubuntu1604.sh# install flow within the environment]]></content>
      <categories>
        <category>学习</category>
        <category>交通仿真</category>
      </categories>
      <tags>
        <tag>琐碎</tag>
        <tag>ubuntu</tag>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo相关命令]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%B7%A5%E5%85%B7%2Fhexo.html</url>
    <content type="text"><![CDATA[Hexo相关命令，以及我对Hexo和Next的修改日志 hexo的apihttps://hexo.io/zh-cn/docs/writing.html hexo的常用命令12345678hexo server -p 4001hexo new [layout] &lt;title&gt;hexo clean hexo g hexo dhexo clean &amp;&amp; hexo g &amp;&amp; hexo dhexo clean &amp;&amp; hexo g &amp;&amp; hexo server -p 4001 评论系统https://ioliu.cn/2017/add-valine-comments-to-your-blog/ 修改日志特定段落缩进 123456789101112// 特定段落(标志ooNoIndent00)缩进// 是因为修改了~\blog\themes\next\source\js\src\bootstaps.js 文件// 添加了下面一段话// 特定段落(标志ooNoIndent00)缩进$('p:contains("ooNoIndent00")').each(function() &#123; var str = $(this).text(); if (str.match("ooNoIndent00")) &#123; var text = $(this).html(); $(this).css('text-indent', '0em'); $(this).html(text.replace('ooNoIndent00', '')); &#125;&#125;); 密码输入 12345678910111213// ~\blog\themes\next\layout\_partials\head.swig&lt;!-- #增加个输入密码的功能 # --&gt;&lt;script&gt; (function()&#123; if('&#123;&#123; page.password &#125;&#125;')&#123; if (prompt('请输入文章密码') !== '&#123;&#123; page.password &#125;&#125;')&#123; alert('密码错误！'); location.href='/' &#125; &#125; &#125;)();&lt;/script&gt; 首页隐藏 1234567891011121314// ~\blog\themes\next\layout\index.swig&lt;!-- #增加个首页隐藏的功能 # --&gt;&#123;% block content %&#125; &lt;section id="posts" class="posts-expand"&gt; &#123;% for post in page.posts %&#125; &#123;% if post.visible !== 'hide' %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;/section&gt; &#123;% include '_partials/pagination.swig' %&#125;&#123;% endblock %&#125; 首行缩进 1234567// ~\blog\themes\next\source\css_custom\custom.styl:// Custom styles.// 设置段落首行缩进（text-indent），调整段落下部间距.post-body p &#123; text-indent: 0em; margin-bottom: 0.8em; &#125; 增加站点搜索功能搜索功能真心好用，当文章多起来的时候，标签提供的作用已经很少了，只能简单索引，搜索却能精确查找，这里我用的依旧是最简单的本地站内搜索。 安装插件 1npm install hexo-generator-searchdb --save 修改站点配置文件 12345search: path: search.xml field: post format: html limit: 10000 修改主题配置文件 12local_search: enable: true 修改hexo文章链接HEXO默认的文章链接形式为domain/year/month/day/postname，默认就是一个四级url，并且可能造成url过长，对搜索引擎是十分不友好的，我们可以改成 domain/postname 的形式。编辑站点_config.yml文件，修改其中的permalink字段改为permalink: :title.html即可。 站点地图https://www.cnblogs.com/php-linux/p/8493181.html]]></content>
      <categories>
        <category>生活</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>琐碎</tag>
        <tag>随手记</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab和GitHub的同步]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%B7%A5%E5%85%B7%2Fgit.html</url>
    <content type="text"><![CDATA[我想可以在GitLab里建库，然后随时可以同步到GitHub上。我使用的是git命令中关于多个远程仓库的命令。在本地有一个GitLab的库后，在git bash内一次输入下面的命令就好。 使用如下命令添加第二个远程仓库。 12345git remote set-url --add oginin http://192.168.100.54/git/gaoxing/gaoxTest.gitgit remote set-url --add oginin http://githubXXXXXhttp://githubXXXXXX : 是在GitHub里的‘clone or download’获得的 查看远程仓库情况。可以看到git上有两个远程仓库的 push 地址。这种方法的好处是每次只需要push 一次就行了。 1git remote -v]]></content>
      <categories>
        <category>生活</category>
        <category>工具</category>
      </categories>
      <tags>
        <tag>琐碎</tag>
        <tag>随手记</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验室索引]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F%E5%8A%9E%E5%85%AC%2F%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%B4%A2%E5%BC%95.html</url>
    <content type="text"><![CDATA[实验室导师简介郑皎凌：硕士生导师 【个人简介】 郑皎凌，女，副教授，生于1981年，中共党员，研究生学历，博士学位。学习计算机专业，获计算机科学与技术专业工学博士学位。现任四川省计算机学会大数据专委会委员. 【研究方向】 1．04(全日制)智能信息处理与知识工程 2．01(全日制)大数据分析与服务 【在研项目】 四川省教育厅重点课题，虚拟社会中个体间往复交互模式挖掘及其对虚拟社团形成和发展的影响 项目负责人 【完成项目】 1．社群大规模协作认知规律和演化模型挖掘，国家自然科学基金青年基金项目，项目负责人，2015年12月完成。 基于干预技术的复杂系统可信演化模型挖掘 四川省教育厅青年基金项目，项目负责人，2013年12月完成。 【发表论文】 1、郑皎凌、唐常杰、乔少杰、杨宁、李川、陈瑜、王悦 ，基于扰动的亚复杂动力系统因果关系挖掘 ，计算机学报, 12期,pp 2548-2563, 2014/12/15 ，EI 2、郑皎凌、舒红平、许源平、乔少杰、文立玉 ，基于社群联盟的冲突消解原则求解图着色问题,电子科技大学学报(自科版)，45(1)，pp 2-16，2016/1/1，EI 3、郑皎凌、舒红平、许源平、乔少杰、文立玉 ，Cooperation Oriented Computing: A Computing Model Based on Emergent Dynamics of Group Cooperation ，Big Data Technology and Applications, 2015/12/25-2015/12/26, pp 218-233, 2015/12/25, EI 4、Jiaoling Zheng，Changjie Tang，Shaojie Qiao，Ning Yang，Yue Wang,Mining Multi-scale Intervention Rules from Time Series and Complex Network,《International Journal of Computational Intelligence Systems》 , 2011 , 4 (4) :728-738，SCI 000297795000025 实验室资料索引 本文档主要作为“实验室数据库”的一个检索目录，以及功能介绍，本数据库依托gitlab总共有三方面的功能： 《实验室数据库》的根目录是：https://gitlab.com/CUITDMLab 《实验室数据库》的“代码库”地址是：https://gitlab.com/CUITDMLab/CodeBase 《实验室数据库》的“记录相关的库”地址是：https://gitlab.com/CUITDMLab/BMdocuments 《实验室数据库》的“学习笔记”：https://gitlab.com/CUITDMLab/StudyNotes CodeBase：储存学生期间做项目，打比赛的代码与数据。 实验室代码与数据请放到GitLab群组下：https://gitlab.com/CUITDMLab/CodeBase ，另外完整的项目请单独开一个“项目”，如果是学习代码，比如像学习了《机器学习实战》自己写的课后代码也请在该目录下新建项目。 BMdocuments：记录会议记录、每位同学的工作进度（一周一次）。 会议记录：请fork在项目BMdocuments，会议记录有学生记录并由老师确认后上传到GitLab。会议记录主要写开会的内容，以及每位学生下一周的学习任务。 学生学习进度：请fork在项目BMdocuments，学生不可以修改会议记录文件夹，只可以修改学生工作文件夹中属于自己的文件。学生工作进度分为两个部分：一、老师安排任务的完成情况。二、本周的学习情况（学了什么，有什么问题？） StudyNotes：记录学习笔记，学习经验。 参考 https://github.com/Jack-Lee-Hiter/AlgorithmsByPython 将学习的总结写到库中StudyNotes 实验室学生索引研17级_张中雷 研17级_邹长杰 研18级_蒋洛锋 研18级_赵大楼]]></content>
      <categories>
        <category>生活</category>
        <category>办公</category>
      </categories>
      <tags>
        <tag>实验室索引</tag>
        <tag>导师介绍</tag>
      </tags>
  </entry>
</search>
